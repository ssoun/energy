import streamlit as st
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain_community.callbacks import get_openai_callback
from langchain.memory import ConversationBufferMemory
from langchain.memory import StreamlitChatMessageHistory
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from langchain.schema.messages import HumanMessage, AIMessage
import tiktoken
import json
import base64

def main():
    st.set_page_config(page_title="kangsinchat", page_icon="ğŸ«")
    st.image('energy.png')
    st.title("_:red[ì—ë„ˆì§€ í•™ìŠµ ë„ìš°ë¯¸ ]_ ğŸ«")
    st.header("ğŸ˜¶ì£¼ì˜!ì´ ì±—ë´‡ì€ ì°¸ê³ ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!", divider='rainbow')

    if "conversation" not in st.session_state:
        clear_button = st.button("ëŒ€í™” ë‚´ìš© ì‚­ì œ", key="clear_button")
        if clear_button:
            st.session_state.chat_history = []
            st.session_state.messages = [{"role": "assistant", "content": "ì—ë„ˆì§€ í•™ìŠµì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!ğŸ˜Š"}]
            st.experimental_rerun()  # í™”ë©´ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ì´ˆê¸°í™”

    if 'messages' not in st.session_state:
        st.session_state['messages'] = [{"role": "assistant",                                          
                                         "content": "ì—ë„ˆì§€ í•™ìŠµì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!ğŸ˜Š"}]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    history = StreamlitChatMessageHistory(key="chat_messages")

    if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
        st.session_state.messages.append({"role": "user", "content": query})

        with st.chat_message("user"):
            st.markdown(query)

        with st.chat_message("assistant"):
            chain = st.session_state.conversation

            with st.spinner("ìƒê° ì¤‘..."):
                result = chain({"question": query})
                with get_openai_callback() as cb:
                    st.session_state.chat_history = result['chat_history']
                response = result['answer']
                source_documents = result['source_documents']

                st.markdown(response)
